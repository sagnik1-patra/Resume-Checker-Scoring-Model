{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956d4aa5-bd3e-4006-ae26-76f4091903aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 10.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.0/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.2 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Dataset shape: (962, 2)\n",
      "       Category                                             Resume\n",
      "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
      "1  Data Science  Education Details \\nMay 2013 to May 2017 B.E  ...\n",
      "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
      "3  Data Science  Skills Ã¢Â€Â¢ R Ã¢Â€Â¢ Python Ã¢Â€Â¢ SAP HANA Ã¢Â€Â¢ Table...\n",
      "4  Data Science  Education Details \\n MCA   YMCAUST,  Faridabad...\n",
      "Labels: {'Data Science': 0, 'HR': 1, 'Advocate': 2, 'Arts': 3, 'Web Designing': 4, 'Mechanical Engineer': 5, 'Sales': 6, 'Health and fitness': 7, 'Civil Engineer': 8, 'Java Developer': 9, 'Business Analyst': 10, 'SAP Developer': 11, 'Automation Testing': 12, 'Electrical Engineering': 13, 'Operations Manager': 14, 'Python Developer': 15, 'DevOps Engineer': 16, 'Network Security Engineer': 17, 'PMO': 18, 'Database': 19, 'Hadoop': 20, 'ETL Developer': 21, 'DotNet Developer': 22, 'Blockchain': 23, 'Testing': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [17:38<00:00, 10.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.9024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [17:38<00:00, 10.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.7094\n",
      "\n",
      "ðŸ“ˆ Classification Report:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "             Data Science       1.00      0.50      0.67         8\n",
      "                       HR       1.00      1.00      1.00         9\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      1.00      1.00         7\n",
      "            Web Designing       1.00      1.00      1.00         9\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "                    Sales       1.00      1.00      1.00         8\n",
      "       Health and fitness       1.00      1.00      1.00         6\n",
      "           Civil Engineer       1.00      1.00      1.00         5\n",
      "           Java Developer       0.94      1.00      0.97        17\n",
      "         Business Analyst       1.00      0.83      0.91         6\n",
      "            SAP Developer       1.00      1.00      1.00         5\n",
      "       Automation Testing       1.00      0.60      0.75         5\n",
      "   Electrical Engineering       1.00      1.00      1.00         6\n",
      "       Operations Manager       1.00      1.00      1.00         8\n",
      "         Python Developer       0.71      1.00      0.83        10\n",
      "          DevOps Engineer       1.00      1.00      1.00        11\n",
      "Network Security Engineer       1.00      1.00      1.00         5\n",
      "                      PMO       0.86      1.00      0.92         6\n",
      "                 Database       1.00      1.00      1.00         7\n",
      "                   Hadoop       1.00      1.00      1.00         8\n",
      "            ETL Developer       1.00      1.00      1.00         8\n",
      "         DotNet Developer       1.00      0.80      0.89         5\n",
      "               Blockchain       1.00      1.00      1.00         8\n",
      "                  Testing       0.88      1.00      0.93        14\n",
      "\n",
      "                 accuracy                           0.96       193\n",
      "                macro avg       0.98      0.95      0.96       193\n",
      "             weighted avg       0.97      0.96      0.96       193\n",
      "\n",
      "âœ… Model and tokenizer saved to 'C:\\Users\\sagni\\Downloads\\Resume Selector\\resume_model'\n",
      "ðŸ”® Predicted Category: Python Developer\n"
     ]
    }
   ],
   "source": [
    "# ðŸš¨ Install dependencies (only first time)\n",
    "!pip install transformers spacy scikit-learn pandas tqdm --quiet\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# ðŸ“¦ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ðŸ“¥ Load Dataset\n",
    "data_path = r\"C:\\Users\\sagni\\Downloads\\Resume Selector\\UpdatedResumeDataSet.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# ðŸ§¹ Clean and Preprocess with SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def preprocess(text):\n",
    "    doc = nlp(str(text).lower())\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "df['clean_text'] = df['Resume'].apply(preprocess)\n",
    "df['label'] = pd.factorize(df['Category'])[0]\n",
    "label2id = dict(zip(pd.factorize(df['Category'])[1], range(len(pd.factorize(df['Category'])[1]))))\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "print(f\"Labels: {label2id}\")\n",
    "\n",
    "# ðŸ”€ Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['clean_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "# ðŸ“š Tokenizer and Dataset\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts, self.labels, self.tokenizer, self.max_len = texts, labels, tokenizer, max_len\n",
    "    def __len__(self): return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(self.texts.iloc[idx], truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "        return {key: val.squeeze(0) for key, val in encodings.items()}, torch.tensor(int(self.labels.iloc[idx]), dtype=torch.long)\n",
    "\n",
    "train_dataset = ResumeDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = ResumeDataset(X_val, y_val, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# ðŸ—ï¸ Model Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label2id))\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# ðŸ”¥ Training\n",
    "epochs = 2  # You can increase to 3-4 for better accuracy\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs, labels_batch = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        outputs = model(**inputs, labels=labels_batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ðŸ“Š Validation\n",
    "model.eval()\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs, labels_batch = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        logits = model(**inputs).logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().detach().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels_batch.numpy())\n",
    "print(\"\\nðŸ“ˆ Classification Report:\\n\", classification_report(y_true, y_pred, target_names=list(label2id.keys())))\n",
    "\n",
    "# ðŸ’¾ Save Model\n",
    "save_dir = r\"C:\\Users\\sagni\\Downloads\\Resume Selector\\resume_model\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"âœ… Model and tokenizer saved to '{save_dir}'\")\n",
    "\n",
    "# ðŸ”® Predict From New Resume\n",
    "def predict_resume(text):\n",
    "    text = preprocess(text)\n",
    "    encoding = tokenizer(text, truncation=True, padding='max_length', max_length=256, return_tensors='pt')\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoding).logits\n",
    "    pred_label = torch.argmax(logits, dim=1).cpu().item()\n",
    "    return id2label[pred_label]\n",
    "\n",
    "# ðŸ§ª Example Prediction\n",
    "sample_resume = \"\"\"\n",
    "    Skills: Python, Data Analysis, Machine Learning\n",
    "    Experience: 3 years as Data Scientist at ABC Corp.\n",
    "    Projects: Predictive analytics, NLP chatbots\n",
    "\"\"\"\n",
    "predicted_category = predict_resume(sample_resume)\n",
    "print(f\"ðŸ”® Predicted Category: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aeddad-7ca7-4814-acab-fe47f36cef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
